---
- hosts: localhost
  gather_facts: false
  tasks:
  - file: name=~/.ssh/mux-* state=absent
  - pip: name=ansible version=2.0.2.0


- hosts: clc:cc:sc:ufs:nc
  vars:
    sysctl_set:
      net.ipv4.ip_local_port_range: 1024 65000
      net.core.rmem_max: 16777216
      net.core.wmem_max: 16777216
      net.ipv4.tcp_rmem: 4096 87380 16777216
      net.ipv4.tcp_wmem: 4096 65536 16777216
      net.ipv4.tcp_max_syn_backlog: 4096
      net.core.netdev_max_backlog: 2500
      vm.min_free_kbytes: 65536
  roles: [common]
  tags: common


- hosts: clc:ufs:sc
  gather_facts: false
  vars:
    sysctl_set:
      net.ipv4.neigh.default.gc_interval: 3600
      net.ipv4.neigh.default.gc_stale_time: 3600
      net.ipv4.neigh.default.gc_thresh1: 1024
      net.ipv4.neigh.default.gc_thresh2: 2048
      net.ipv4.neigh.default.gc_thresh3: 4096
      net.ipv4.ip_forward: 1
  roles: [eucalyptus-java]


- hosts: clc
  gather_facts: false
  vars:
    euctl_set:
      authentication.access_keys_limit: 20
      authentication.signing_certificates_limit: 20
      authentication.credential_download_generate_certificate: Limited
      services.imaging.worker.instance_type: m1.medium
      services.loadbalancing.worker.instance_type: m1.medium
      cloudformation.region: eucalyptus
      objectstorage.providerclient: riakcs
      objectstorage.s3provider.s3endpoint: "{{ ceph_backend_endpoint }}"
      objectstorage.s3provider.s3accesskey: "{{ ceph_backend_accesskey }}"
      objectstorage.s3provider.s3secretkey: "{{ ceph_backend_secretkey }}"
      system.dns.dnsdomain: "{{ dns_domain }}"
      bootstrap.webservices.use_instance_dns: true
      bootstrap.webservices.use_dns_delegation: true
      #cloud.network.network_configuration: '@network.json'
      #AZ-1
      az-1.cluster.networkmode: VPCMIDO
      az-1.storage.blockstoragemanager: ceph-rbd
      az-1.storage.cephvolumepools: "{{ ceph_backend_volumepools }}"
      az-1.storage.cephsnapshotpools: "{{ ceph_backend_snapshotpools }}"
      #AZ-2
      az-2.cluster.networkmode: VPCMIDO
      az-2.storage.blockstoragemanager: ceph-rbd
      az-2.storage.cephvolumepools: "{{ ceph_backend_volumepools }}"
      az-2.storage.cephsnapshotpools: "{{ ceph_backend_snapshotpools }}"
      storage.global_total_snapshot_size_limit_gb: 200
  environment:
    AWS_DEFAULT_REGION: "{{ dns_domain }}"
  roles:
  - euca-clc
  - midoapi
  tags: clc

- hosts: nsd
  gather_facts: false
  roles:
  - zookeeper
  - cassandra
  tags: nsd


- hosts: cc:nc
  gather_facts: false
  roles: [midolman]


- hosts: ufs
  gather_facts: false
  roles: [euca-ufs]
  tags: ufs


- hosts: cc:sc
  gather_facts: false
  vars:
    sysctl_set:
      net.ipv4.ip_forward: 1
  roles:
  - euca-ccsc
  - cephclient
  tags: ccsc


- hosts: nc
  gather_facts: false
  vars:
    sysctl_set:
      net.ipv4.ip_forward: 1
      net.bridge.bridge-nf-call-iptables: 1
  roles:
  - euca-nc
  - cephclient
  tags: nc

- hosts: clc
  gather_facts: false
  roles: [euca-register]
  tags: register


# midonet-cli -A --midonet-url=http://127.0.0.1:8080/midonet-api -e list tunnel-zone | grep 'name.mido-tz ' || \
# midonet-cli -A --midonet-url=http://127.0.0.1:8080/midonet-api -e add tunnel-zone name mido-tz type gre
# Get TZ - midonet-cli -A --midonet-url=http://127.0.0.1:8080/midonet-api -e list tunnel-zone name mido-tz
# Get TZ member - midonet-cli -A --midonet-url=http://127.0.0.1:8080/midonet-api -e list tunnel-zone name mido-tz member
# Get Hosts - midonet-cli -A --midonet-url=http://127.0.0.1:8080/midonet-api -e host list
# Add host to TZ -midonet-cli -A --midonet-url=http://127.0.0.1:8080/midonet-api -e tunnel-zone 4d1fd56a-ddd9-4adc-8c7b-b1317bf38340 add member host 76555c97-3094-4381-964e-b25ba0ebb83a address 10.143.58.145
# euca-create-vpc 192.168.0.0/16 --tenancy default
# source ~/.sysrc; esi-manage-stack -a create imaging
